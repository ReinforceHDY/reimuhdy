{
  "cells": [
    {
      "metadata": {
        "_uuid": "56c7ec91d6d2f7e6f9807ecf425b89894636372f"
      },
      "cell_type": "markdown",
      "source": "## bias 和variance对比实现  \n\n#### 这节课我们在人工点集上利用不同自由度的多项式进行线性回归，对比不同自由度下模型的bias和variance"
    },
    {
      "metadata": {
        "collapsed": true,
        "trusted": false,
        "_uuid": "ef5eb6070af20252320394bdc7a133e5d9abd5a6"
      },
      "cell_type": "code",
      "source": "%matplotlib inline\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error as mse\n\n# 数据集个数\nNum_datasets = 50\nnoise_level = 0.5\n\n# 最大的degree\nmax_degree = 10\n\n# 每个数据集里的数据个数\nN = 25\n\n# 用于训练的数据数\ntrainN = int(N * 0.9)\n\nnp.random.seed(2)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "cb3af3594e27c4cace4c7479be8949c9948ca086"
      },
      "cell_type": "markdown",
      "source": ""
    },
    {
      "metadata": {
        "collapsed": true,
        "trusted": false,
        "_uuid": "bda7de1ecba3654b565f1580e85e02714a2dfef0"
      },
      "cell_type": "code",
      "source": "def make_poly(x, degree):\n    \"\"\"\n    input: x  N by 1\n    output: N by degree + 1\n    \"\"\"\n    N = len(x)\n    result = np.empty((N, degree+1))\n    for d in range(degree + 1):\n        result[:,d] = x ** d\n        if d > 1:\n            result[:, d] = (result[:, d] - result[:, d].mean()) / result[:,d].std()\n    return result\n\ndef f(X):\n    \"\"\"\n    input: x\n    output: sin(x)\n    \"\"\"\n    return np.sin(X)\n        ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "5ebf6ff391b50b8b12c8cd5aa19210c1c7ee61f9"
      },
      "cell_type": "markdown",
      "source": "#### 目标函数为sin   "
    },
    {
      "metadata": {
        "trusted": false,
        "_uuid": "47085a9ee0884a117f14ae3a85da6d2f95edf313",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "x_axis = np.linspace(-np.pi, np.pi, 100)\ny_axis = f(x_axis)\nplt.plot(x_axis, y_axis)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "trusted": false,
        "_uuid": "48661a47d21d8ae6051be83543fcb608977e31e9"
      },
      "cell_type": "code",
      "source": "# 基础点集\nX = np.linspace(-np.pi, np.pi, N)\nnp.random.shuffle(X)\nf_X = f(X)\n\n# allData: N by 13\nallData = make_poly(X, max_degree)\n\n\n# 每一个训练集上的训练得分与测试得分\ntrain_scores = np.zeros((Num_datasets, max_degree))\ntest_scores = np.zeros((Num_datasets, max_degree))\n\n\ntrain_predictions = np.zeros((trainN, Num_datasets, max_degree))\nprediction_curves = np.zeros((100, Num_datasets, max_degree))\n\nmodel = LinearRegression()\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false,
        "_uuid": "f65e7b8426749f182efdfd0ef4937273aeedb529",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "plt.scatter(X, f_X)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "9498ee55784803dc89adc6afdfe85829b85f2a57"
      },
      "cell_type": "markdown",
      "source": "#### 每一个数据集上用不同degree的多项式拟合"
    },
    {
      "metadata": {
        "collapsed": true,
        "trusted": false,
        "_uuid": "5a454803cf0d7ea3a2ae2bfe26642d9d0e60616e"
      },
      "cell_type": "code",
      "source": "for k in range(Num_datasets):\n    \n    # 每个数据集需要不一样~\n    Y = f_X + np.random.randn(N) * noise_level\n    \n    trainX, testX = allData[:trainN], allData[trainN:]\n    trainY, testY = Y[:trainN], Y[trainN:]\n    \n    for d in range(max_degree):\n        \n        # 模型学习\n        model.fit(trainX[:,:d+2], trainY)\n        \n        # 在allData上的预测结果\n        all_predictions = model.predict(allData[:, :d+2])\n        \n        # 预测并记录一下我们的目标函数\n        x_axis_poly = make_poly(x_axis, d+1)    # true poly x\n        axis_predictions = model.predict(x_axis_poly)   # true y\n        prediction_curves[:, k, d] = axis_predictions\n        \n        train_prediction = all_predictions[:trainN]\n        test_prediction = all_predictions[trainN:]\n        \n        train_predictions[:, k, d] = train_prediction # 用于计算bias and varaince \n        \n        \n        #计算并存储训练集和测试集上的分数\n        train_score = mse(train_prediction, trainY)\n        test_score = mse(test_prediction, testY)\n        train_scores[k, d] = train_score\n        test_scores[k, d] = test_score\n            ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "dbe329e13ec7a89b410e613339bd0d795b729355"
      },
      "cell_type": "markdown",
      "source": "#### 画出每一个degree下，50个数据集上预测结果以及预测结果的平均"
    },
    {
      "metadata": {
        "trusted": false,
        "_uuid": "6491f984d14c15a70d5c1093679d27e0c741e630",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "for d in range(max_degree):\n    for k in range(Num_datasets):\n        plt.plot(x_axis, prediction_curves[:,k,d], color='green', alpha=0.5)\n    plt.plot(x_axis, prediction_curves[:,:,d].mean(axis=1), color='blue', linewidth=2)\n    plt.title(\"curves for degree = %d\" % (d + 1))\n    plt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "bf343d3d9cab22e7b89c63dd2fd3146ce106dcd0"
      },
      "cell_type": "markdown",
      "source": "#### 计算bias跟variance  \n\n- 一种degree对应一种模型  \n- 给定一种模型，计算该模型在50个数据集上的预测结果的平均  \n- 给定一种模型，计算该模型在50个数据集上预测结果的方差"
    },
    {
      "metadata": {
        "collapsed": true,
        "trusted": false,
        "_uuid": "f61cc8b9ee19a588431036993d83c107e0a8759e"
      },
      "cell_type": "code",
      "source": "average_train_prediction = np.zeros((trainN, max_degree))\nsquared_bias = np.zeros(max_degree)\n\ntrueY_train = f_X[:trainN]\nfor d in range(max_degree):\n    for i in range(trainN):\n        average_train_prediction[i,d] = train_predictions[i,:,d].mean()\n    squared_bias[d] = ((average_train_prediction[:,d] - trueY_train) ** 2).mean()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "trusted": false,
        "_uuid": "d031a0ddef39e7403ae1a785bce98931f7fe4cf7"
      },
      "cell_type": "code",
      "source": "variances = np.zeros((trainN, max_degree))\nfor d in range(max_degree):\n    for i in range(trainN):\n        difference = train_predictions[i,:,d] - average_train_prediction[i,d]\n        variances[i,d] = np.dot(difference, difference) / Num_datasets\nvariance = variances.mean(axis=0)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "fe625a7d858ff771ad8a1091f8036c2e183a31be"
      },
      "cell_type": "markdown",
      "source": "#### 作图   \n- 以degree为横轴，以$bias^2$为纵轴  \n- 以degree为横轴，以$variance$为纵轴  \n- 以degree为横轴，以测试集分数为纵轴  \n- 以degree为横轴，以$bias^2 + variance$为纵轴"
    },
    {
      "metadata": {
        "trusted": false,
        "_uuid": "b4fc70458fd8a03c39a2de17d41b65179e287d74",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "degrees = np.arange(max_degree) + 1\nbest_degree = np.argmin(test_scores.mean(axis=0)) + 1\n\nplt.plot(degrees, squared_bias, label='squared bias')\nplt.plot(degrees, variance, label = 'variance')\nplt.plot(degrees, test_scores.mean(axis=0), label='test scores')\nplt.plot(degrees, squared_bias + variance, label='squared bias + variance')\nplt.axvline(x=best_degree, linestyle='--', label='best complexity')\nplt.legend()\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "71c602ffa5413c1540d529e0e11179f027c0a7eb"
      },
      "cell_type": "markdown",
      "source": "#### 作图  \n- 以degree为横轴，以训练集分数为纵轴  \n- 以degree为横轴，以测试集分数为纵轴"
    },
    {
      "metadata": {
        "trusted": false,
        "_uuid": "c7368a4b581d8813c913a22fd27f77e319789b16",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "plt.plot(degrees, train_scores.mean(axis=0), label='train scores')\nplt.plot(degrees, test_scores.mean(axis=0), label= 'test scores')\nplt.axvline(x=best_degree, linestyle='--', label='best complexity')\nplt.legend()\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "trusted": false,
        "_uuid": "c8713fdeffb346f27cf04a1f0e4738f45fdbd83d"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}